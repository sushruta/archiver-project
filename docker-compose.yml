
version: '3'

volumes:
  #mysql-data:
  kafka-data:
  #elastic-data:
  hadoop-data:

services:
  zookeeper:
    image: asappinc/alpine_zookeeper34
    ports:
    - "2181:2181"
    - "6123:6123"
    healthcheck:
      test: "nc -z localhost 2181"
      interval: 1s
      retries: 120

  kafka:
    image: asappinc/alpine_kafka1
    ports:
    - "0.0.0.0:9092:9092"
    links:
    - zookeeper
    environment:
      KAFKA_CREATE_TOPICS: "first_topic:4:1,second_topic:8:1,third_topic:12:1"
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_PORT: 9092
      ## NOTE: if running kafka test you must do this inside the "dev" versions of containers
      ## as kafka does not really do well w/o real IPs or real Hostnames which outside a docker-compose
      ## network is difficult to fiddles with
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      # log.retention.hours
      KAFKA_LOG_RETENTION_HOURS: 1
      #log.segment.bytes=1073741824
      KAFKA_LOG_SEGMENT_BYTES: 1048576
    healthcheck:
      test: "nc -z localhost 9092"
      interval: 1s
      retries: 120
    volumes:
    - kafka-data:/kafka

  ##mysql:
  ##  image: mysql:5.7
  ##  ports:
  ##  # different ports to allow a local host installed mysql as well
  ##  - "0.0.0.0:3318:3306"
  ##  command: ["mysqld", "--explicit-defaults-for-timestamp=1"]
  ##  environment:
  ##    MYSQL_DATABASE: archive
  ##    MYSQL_ROOT_PASSWORD: archive
  ##    MYSQL_HOST: "%"
  ##  volumes:
  ##  - mysql-data:/var/lib/mysql

  ##elasticsearch:
  ##  image: elasticsearch:5.5.2
  ##  ports:
  ##  - "0.0.0.0:9200:9200"
  ##  volumes:
  ##  - elastic-data:/usr/share/elasticsearch/data

  go-app:
    image: asappinc/goapp
    build:
      context: ./go-stuff/
      dockerfile: Dockerfile

  hadoop:
    image: asappinc_challenge/hadoop
    build:
      context: ./hadoop-stuff/
      dockerfile: Dockerfile
    ports:
    - "0.0.0.0:50010:50010"
    - "0.0.0.0:50020:50020"
    - "0.0.0.0:50070:50070"
    - "0.0.0.0:50075:50075"
    - "0.0.0.0:50090:50090"
    - "0.0.0.0:8020:8020"
    - "0.0.0.0:9000:9000"
    - "0.0.0.0:10020:10020"
    - "0.0.0.0:19888:19888"
    - "0.0.0.0:8030:8030"
    - "0.0.0.0:8031:8031"
    - "0.0.0.0:8032:8032"
    - "0.0.0.0:8033:8033"
    - "0.0.0.0:8040:8040"
    - "0.0.0.0:8042:8042"
    - "0.0.0.0:8088:8088"
    - "0.0.0.0:49707:49707"
    - "0.0.0.0:2122:2122"
    links:
    - zookeeper

  producer:
    image: asappinc/goapp
    command: ["go", "run", "cmd/produce/produce.go"]
    working_dir: /gobits/src/github.com/asappinc/challenge-di-eng
    environment:
      KAFKA_BROKERS: kafka:9092
      KAFKA_TOPICS: "first_topic,second_topic,third_topic"
    links:
      - kafka

  echoconsumer:
    image: asappinc/goapp
    command: ["go", "run", "cmd/archiver/archiver.go"] # "cmd/echoconsume/echoconsume.go"]
    working_dir: /gobits/src/github.com/asappinc/challenge-di-eng
    environment:
      KAFKA_BROKERS: kafka:9092
      KAFKA_TOPICS: "first_topic,second_topic,third_topic"
    links:
    - kafka

  archiver:
    image: asappinc/flinkapp
    build:
      context: ./flink-stuff/
      dockerfile: Dockerfile
    command: ["/usr/local/bin/entrypoint.sh"]
    links:
    - kafka
    - hadoop
    - zookeeper

  ##dev:
  ##  image: asappinc_challenge/archiver
  ##  command: ["bash"] # go", "run", "cmd/archiver/archiver.go"]
  ##  working_dir: /gobits/src/github.com/asappinc/challenge-di-eng
  ##  environment:
  ##    MYSQL_HOST: mysql
  ##    MYSQL_PASSWORD: archive
  ##    MYSQL_DB: archive
  ##    MYSQL_PORT: 3306

  ##    ELASTICSEARCH: elasticsearch:9092
  ##    ELASTICSEARCH_INDEX: archive

  ##    KAFKA_BROKERS: kafka:9092
  ##    KAFKA_TOPICS: "first_topic,second_topic,third_topic"
  ##  volumes:
  ##    - $PWD/go-stuff/src/github.com/asappinc/challenge-di-eng:/gobits/src/github.com/asappinc/challenge-di-eng

  ##  links:
  ##    #- mysql
  ##    - kafka
  ##    - hadoop
